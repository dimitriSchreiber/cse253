{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Training a classifier\n",
    "=====================\n",
    "\n",
    "This is it. You have seen how to define neural networks, compute loss and make\n",
    "updates to the weights of the network.\n",
    "\n",
    "Now you might be thinking,\n",
    "\n",
    "What about data?\n",
    "----------------\n",
    "\n",
    "Generally, when you have to deal with image, text, audio or video data,\n",
    "you can use standard python packages that load data into a numpy array.\n",
    "Then you can convert this array into a ``torch.*Tensor``.\n",
    "\n",
    "-  For images, packages such as Pillow, OpenCV are useful.\n",
    "-  For audio, packages such as scipy and librosa\n",
    "-  For text, either raw Python or Cython based loading, or NLTK and\n",
    "   SpaCy are useful.\n",
    "\n",
    "Specifically for ``vision``, we have created a package called\n",
    "``torchvision``, that has data loaders for common datasets such as\n",
    "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
    "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
    "\n",
    "This provides a huge convenience and avoids writing boilerplate code.\n",
    "\n",
    "For this tutorial, we will use the CIFAR10 dataset.\n",
    "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
    "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
    "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    ".. figure:: /_static/img/cifar10.png\n",
    "   :alt: cifar10\n",
    "\n",
    "   cifar10\n",
    "\n",
    "\n",
    "Training an image classifier\n",
    "----------------------------\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolution Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "1. Loading and normalizing CIFAR10\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " frog truck  ship  ship\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c3418b9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a Convolution Neural Network\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "Copy the neural network from the Neural Networks section before and modify it to\n",
    "take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a Loss function and optimizer\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the network\n",
    "^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.233\n",
      "[1,  4000] loss: 1.858\n",
      "[1,  6000] loss: 1.671\n",
      "[1,  8000] loss: 1.582\n",
      "[1, 10000] loss: 1.537\n",
      "[1, 12000] loss: 1.481\n",
      "[2,  2000] loss: 1.425\n",
      "[2,  4000] loss: 1.379\n",
      "[2,  6000] loss: 1.389\n",
      "[2,  8000] loss: 1.357\n",
      "[2, 10000] loss: 1.358\n",
      "[2, 12000] loss: 1.332\n",
      "[3,  2000] loss: 1.261\n",
      "[3,  4000] loss: 1.252\n",
      "[3,  6000] loss: 1.233\n",
      "[3,  8000] loss: 1.251\n",
      "[3, 10000] loss: 1.241\n",
      "[3, 12000] loss: 1.222\n",
      "[4,  2000] loss: 1.133\n",
      "[4,  4000] loss: 1.181\n",
      "[4,  6000] loss: 1.149\n",
      "[4,  8000] loss: 1.154\n",
      "[4, 10000] loss: 1.142\n",
      "[4, 12000] loss: 1.148\n",
      "[5,  2000] loss: 1.053\n",
      "[5,  4000] loss: 1.075\n",
      "[5,  6000] loss: 1.097\n",
      "[5,  8000] loss: 1.075\n",
      "[5, 10000] loss: 1.091\n",
      "[5, 12000] loss: 1.086\n",
      "[6,  2000] loss: 0.981\n",
      "[6,  4000] loss: 1.028\n",
      "[6,  6000] loss: 1.022\n",
      "[6,  8000] loss: 1.025\n",
      "[6, 10000] loss: 1.019\n",
      "[6, 12000] loss: 1.038\n",
      "[7,  2000] loss: 0.930\n",
      "[7,  4000] loss: 0.965\n",
      "[7,  6000] loss: 0.958\n",
      "[7,  8000] loss: 0.989\n",
      "[7, 10000] loss: 1.002\n",
      "[7, 12000] loss: 0.983\n",
      "[8,  2000] loss: 0.904\n",
      "[8,  4000] loss: 0.930\n",
      "[8,  6000] loss: 0.909\n",
      "[8,  8000] loss: 0.911\n",
      "[8, 10000] loss: 0.952\n",
      "[8, 12000] loss: 0.978\n",
      "[9,  2000] loss: 0.851\n",
      "[9,  4000] loss: 0.893\n",
      "[9,  6000] loss: 0.893\n",
      "[9,  8000] loss: 0.904\n",
      "[9, 10000] loss: 0.918\n",
      "[9, 12000] loss: 0.910\n",
      "[10,  2000] loss: 0.808\n",
      "[10,  4000] loss: 0.835\n",
      "[10,  6000] loss: 0.874\n",
      "[10,  8000] loss: 0.873\n",
      "[10, 10000] loss: 0.882\n",
      "[10, 12000] loss: 0.893\n",
      "[11,  2000] loss: 0.766\n",
      "[11,  4000] loss: 0.799\n",
      "[11,  6000] loss: 0.838\n",
      "[11,  8000] loss: 0.869\n",
      "[11, 10000] loss: 0.872\n",
      "[11, 12000] loss: 0.858\n",
      "[12,  2000] loss: 0.747\n",
      "[12,  4000] loss: 0.778\n",
      "[12,  6000] loss: 0.830\n",
      "[12,  8000] loss: 0.823\n",
      "[12, 10000] loss: 0.851\n",
      "[12, 12000] loss: 0.843\n",
      "[13,  2000] loss: 0.739\n",
      "[13,  4000] loss: 0.751\n",
      "[13,  6000] loss: 0.811\n",
      "[13,  8000] loss: 0.800\n",
      "[13, 10000] loss: 0.807\n",
      "[13, 12000] loss: 0.801\n",
      "[14,  2000] loss: 0.710\n",
      "[14,  4000] loss: 0.748\n",
      "[14,  6000] loss: 0.767\n",
      "[14,  8000] loss: 0.795\n",
      "[14, 10000] loss: 0.811\n",
      "[14, 12000] loss: 0.802\n",
      "[15,  2000] loss: 0.694\n",
      "[15,  4000] loss: 0.725\n",
      "[15,  6000] loss: 0.744\n",
      "[15,  8000] loss: 0.765\n",
      "[15, 10000] loss: 0.779\n",
      "[15, 12000] loss: 0.802\n",
      "[16,  2000] loss: 0.679\n",
      "[16,  4000] loss: 0.690\n",
      "[16,  6000] loss: 0.716\n",
      "[16,  8000] loss: 0.773\n",
      "[16, 10000] loss: 0.783\n",
      "[16, 12000] loss: 0.806\n",
      "[17,  2000] loss: 0.661\n",
      "[17,  4000] loss: 0.694\n",
      "[17,  6000] loss: 0.738\n",
      "[17,  8000] loss: 0.756\n",
      "[17, 10000] loss: 0.744\n",
      "[17, 12000] loss: 0.755\n",
      "[18,  2000] loss: 0.648\n",
      "[18,  4000] loss: 0.686\n",
      "[18,  6000] loss: 0.722\n",
      "[18,  8000] loss: 0.738\n",
      "[18, 10000] loss: 0.757\n",
      "[18, 12000] loss: 0.766\n",
      "[19,  2000] loss: 0.626\n",
      "[19,  4000] loss: 0.659\n",
      "[19,  6000] loss: 0.716\n",
      "[19,  8000] loss: 0.736\n",
      "[19, 10000] loss: 0.756\n",
      "[19, 12000] loss: 0.731\n",
      "[20,  2000] loss: 0.620\n",
      "[20,  4000] loss: 0.671\n",
      "[20,  6000] loss: 0.696\n",
      "[20,  8000] loss: 0.698\n",
      "[20, 10000] loss: 0.716\n",
      "[20, 12000] loss: 0.743\n",
      "[21,  2000] loss: 0.622\n",
      "[21,  4000] loss: 0.646\n",
      "[21,  6000] loss: 0.698\n",
      "[21,  8000] loss: 0.703\n",
      "[21, 10000] loss: 0.720\n",
      "[21, 12000] loss: 0.733\n",
      "[22,  2000] loss: 0.590\n",
      "[22,  4000] loss: 0.632\n",
      "[22,  6000] loss: 0.682\n",
      "[22,  8000] loss: 0.674\n",
      "[22, 10000] loss: 0.717\n",
      "[22, 12000] loss: 0.746\n",
      "[23,  2000] loss: 0.603\n",
      "[23,  4000] loss: 0.632\n",
      "[23,  6000] loss: 0.681\n",
      "[23,  8000] loss: 0.682\n",
      "[23, 10000] loss: 0.712\n",
      "[23, 12000] loss: 0.732\n",
      "[24,  2000] loss: 0.606\n",
      "[24,  4000] loss: 0.590\n",
      "[24,  6000] loss: 0.686\n",
      "[24,  8000] loss: 0.694\n",
      "[24, 10000] loss: 0.703\n",
      "[24, 12000] loss: 0.714\n",
      "[25,  2000] loss: 0.586\n",
      "[25,  4000] loss: 0.635\n",
      "[25,  6000] loss: 0.662\n",
      "[25,  8000] loss: 0.674\n",
      "[25, 10000] loss: 0.710\n",
      "[25, 12000] loss: 0.695\n",
      "[26,  2000] loss: 0.575\n",
      "[26,  4000] loss: 0.635\n",
      "[26,  6000] loss: 0.615\n",
      "[26,  8000] loss: 0.674\n",
      "[26, 10000] loss: 0.707\n",
      "[26, 12000] loss: 0.716\n",
      "[27,  2000] loss: 0.576\n",
      "[27,  4000] loss: 0.633\n",
      "[27,  6000] loss: 0.642\n",
      "[27,  8000] loss: 0.670\n",
      "[27, 10000] loss: 0.679\n",
      "[27, 12000] loss: 0.710\n",
      "[28,  2000] loss: 0.569\n",
      "[28,  4000] loss: 0.612\n",
      "[28,  6000] loss: 0.647\n",
      "[28,  8000] loss: 0.673\n",
      "[28, 10000] loss: 0.671\n",
      "[28, 12000] loss: 0.701\n",
      "[29,  2000] loss: 0.586\n",
      "[29,  4000] loss: 0.613\n",
      "[31,  4000] loss: 0.621\n",
      "[31,  6000] loss: 0.624\n",
      "[31,  8000] loss: 0.663\n",
      "[31, 10000] loss: 0.679\n",
      "[31, 12000] loss: 0.698\n",
      "[32,  2000] loss: 0.549\n",
      "[32,  4000] loss: 0.618\n",
      "[32,  6000] loss: 0.638\n",
      "[32,  8000] loss: 0.695\n",
      "[32, 10000] loss: 0.670\n",
      "[32, 12000] loss: 0.650\n",
      "[33,  2000] loss: 0.556\n",
      "[33,  4000] loss: 0.612\n",
      "[33,  6000] loss: 0.624\n",
      "[33,  8000] loss: 0.650\n",
      "[33, 10000] loss: 0.654\n",
      "[33, 12000] loss: 0.685\n",
      "[34,  2000] loss: 0.573\n",
      "[34,  4000] loss: 0.589\n",
      "[34,  6000] loss: 0.640\n",
      "[34,  8000] loss: 0.668\n",
      "[34, 10000] loss: 0.654\n",
      "[34, 12000] loss: 0.684\n",
      "[35,  2000] loss: 0.565\n",
      "[35,  4000] loss: 0.589\n",
      "[35,  6000] loss: 0.627\n",
      "[35,  8000] loss: 0.657\n",
      "[35, 10000] loss: 0.666\n",
      "[35, 12000] loss: 0.681\n",
      "[36,  2000] loss: 0.553\n",
      "[36,  4000] loss: 0.623\n",
      "[36,  6000] loss: 0.620\n",
      "[36,  8000] loss: 0.663\n",
      "[36, 10000] loss: 0.673\n",
      "[36, 12000] loss: 0.680\n",
      "[37,  2000] loss: 0.551\n",
      "[37,  4000] loss: 0.585\n",
      "[37,  6000] loss: 0.618\n",
      "[37,  8000] loss: 0.634\n",
      "[37, 10000] loss: 0.663\n",
      "[37, 12000] loss: 0.683\n",
      "[38,  2000] loss: 0.575\n",
      "[38,  4000] loss: 0.594\n",
      "[38,  6000] loss: 0.620\n",
      "[38,  8000] loss: 0.641\n",
      "[38, 10000] loss: 0.653\n",
      "[38, 12000] loss: 0.662\n",
      "[39,  2000] loss: 0.555\n",
      "[39,  4000] loss: 0.576\n",
      "[39,  6000] loss: 0.639\n",
      "[39,  8000] loss: 0.648\n",
      "[39, 10000] loss: 0.656\n",
      "[39, 12000] loss: 0.643\n",
      "[40,  2000] loss: 0.548\n",
      "[40,  4000] loss: 0.613\n",
      "[40,  6000] loss: 0.616\n",
      "[40,  8000] loss: 0.646\n",
      "[40, 10000] loss: 0.659\n",
      "[40, 12000] loss: 0.669\n",
      "[41,  2000] loss: 0.571\n",
      "[41,  4000] loss: 0.581\n",
      "[41,  6000] loss: 0.642\n",
      "[41,  8000] loss: 0.615\n",
      "[41, 10000] loss: 0.661\n",
      "[41, 12000] loss: 0.671\n",
      "[42,  2000] loss: 0.541\n",
      "[42,  4000] loss: 0.605\n",
      "[42,  6000] loss: 0.613\n",
      "[42,  8000] loss: 0.624\n",
      "[42, 10000] loss: 0.658\n",
      "[42, 12000] loss: 0.653\n",
      "[43,  2000] loss: 0.557\n",
      "[43,  4000] loss: 0.594\n",
      "[43,  6000] loss: 0.633\n",
      "[43,  8000] loss: 0.660\n",
      "[43, 10000] loss: 0.682\n",
      "[43, 12000] loss: 0.678\n",
      "[44,  2000] loss: 0.569\n",
      "[44,  4000] loss: 0.594\n",
      "[44,  6000] loss: 0.671\n",
      "[44,  8000] loss: 0.655\n",
      "[44, 10000] loss: 0.686\n",
      "[44, 12000] loss: 0.664\n",
      "[45,  2000] loss: 0.554\n",
      "[45,  4000] loss: 0.568\n",
      "[45,  6000] loss: 0.592\n",
      "[45,  8000] loss: 0.629\n",
      "[45, 10000] loss: 0.644\n",
      "[45, 12000] loss: 0.655\n",
      "[46,  2000] loss: 0.536\n",
      "[46,  4000] loss: 0.579\n",
      "[46,  6000] loss: 0.612\n",
      "[46,  8000] loss: 0.664\n",
      "[46, 10000] loss: 0.668\n",
      "[46, 12000] loss: 0.657\n",
      "[47,  2000] loss: 0.547\n",
      "[47,  4000] loss: 0.577\n",
      "[47,  6000] loss: 0.618\n",
      "[47,  8000] loss: 0.605\n",
      "[47, 10000] loss: 0.662\n",
      "[47, 12000] loss: 0.639\n",
      "[48,  2000] loss: 0.580\n",
      "[48,  4000] loss: 0.592\n",
      "[48,  6000] loss: 0.624\n",
      "[48,  8000] loss: 0.653\n",
      "[48, 10000] loss: 0.685\n",
      "[48, 12000] loss: 0.622\n",
      "[49,  2000] loss: 0.566\n",
      "[49,  4000] loss: 0.605\n",
      "[49,  6000] loss: 0.617\n",
      "[49,  8000] loss: 0.634\n",
      "[49, 10000] loss: 0.666\n",
      "[49, 12000] loss: 0.680\n",
      "[50,  2000] loss: 0.555\n",
      "[50,  4000] loss: 0.632\n",
      "[50,  6000] loss: 0.634\n",
      "[50,  8000] loss: 0.643\n",
      "[50, 10000] loss: 0.667\n",
      "[50, 12000] loss: 0.668\n",
      "[51,  2000] loss: 0.553\n",
      "[51,  4000] loss: 0.599\n",
      "[51,  6000] loss: 0.618\n",
      "[51,  8000] loss: 0.656\n",
      "[51, 10000] loss: 0.674\n",
      "[51, 12000] loss: 0.638\n",
      "[52,  2000] loss: 0.571\n",
      "[52,  4000] loss: 0.613\n",
      "[52,  6000] loss: 0.593\n",
      "[52,  8000] loss: 0.619\n",
      "[52, 10000] loss: 0.697\n",
      "[52, 12000] loss: 0.667\n",
      "[53,  2000] loss: 0.558\n",
      "[53,  4000] loss: 0.571\n",
      "[53,  6000] loss: 0.643\n",
      "[53,  8000] loss: 0.653\n",
      "[53, 10000] loss: 0.668\n",
      "[53, 12000] loss: 0.687\n",
      "[54,  2000] loss: 0.563\n",
      "[54,  4000] loss: 0.603\n",
      "[54,  6000] loss: 0.627\n",
      "[54,  8000] loss: 0.639\n",
      "[54, 10000] loss: 0.659\n",
      "[54, 12000] loss: 0.676\n",
      "[55,  2000] loss: 0.534\n",
      "[55,  4000] loss: 0.611\n",
      "[55,  6000] loss: 0.628\n",
      "[55,  8000] loss: 0.607\n",
      "[55, 10000] loss: 0.651\n",
      "[55, 12000] loss: 0.687\n",
      "[56,  2000] loss: 0.585\n",
      "[56,  4000] loss: 0.585\n",
      "[56,  6000] loss: 0.648\n",
      "[56,  8000] loss: 0.643\n",
      "[56, 10000] loss: 0.660\n",
      "[56, 12000] loss: 0.695\n",
      "[57,  2000] loss: 0.536\n",
      "[57,  4000] loss: 0.620\n",
      "[57,  6000] loss: 0.628\n",
      "[57,  8000] loss: 0.638\n",
      "[57, 10000] loss: 0.680\n",
      "[57, 12000] loss: 0.648\n",
      "[58,  2000] loss: 0.594\n",
      "[58,  4000] loss: 0.626\n",
      "[58,  6000] loss: 0.607\n",
      "[58,  8000] loss: 0.635\n",
      "[58, 10000] loss: 0.658\n",
      "[58, 12000] loss: 0.664\n",
      "[59,  2000] loss: 0.539\n",
      "[59,  4000] loss: 0.586\n",
      "[59,  6000] loss: 0.617\n",
      "[59,  8000] loss: 0.632\n",
      "[59, 10000] loss: 0.645\n",
      "[59, 12000] loss: 0.668\n",
      "[60,  2000] loss: 0.584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60,  4000] loss: 0.596\n",
      "[60,  6000] loss: 0.616\n",
      "[60,  8000] loss: 0.628\n",
      "[60, 10000] loss: 0.660\n",
      "[60, 12000] loss: 0.683\n",
      "[61,  2000] loss: 0.565\n",
      "[61,  4000] loss: 0.630\n",
      "[61,  6000] loss: 0.636\n",
      "[61,  8000] loss: 0.661\n",
      "[61, 10000] loss: 0.674\n",
      "[61, 12000] loss: 0.702\n",
      "[62,  2000] loss: 0.565\n",
      "[62,  4000] loss: 0.569\n",
      "[62,  6000] loss: 0.606\n",
      "[62,  8000] loss: 0.671\n",
      "[62, 10000] loss: 0.690\n",
      "[62, 12000] loss: 0.668\n",
      "[63,  2000] loss: 0.575\n",
      "[63,  4000] loss: 0.600\n",
      "[63,  6000] loss: 0.610\n",
      "[63,  8000] loss: 0.632\n",
      "[63, 10000] loss: 0.689\n",
      "[63, 12000] loss: 0.668\n",
      "[64,  2000] loss: 0.549\n",
      "[64,  4000] loss: 0.588\n",
      "[64,  6000] loss: 0.654\n",
      "[64,  8000] loss: 0.634\n",
      "[64, 10000] loss: 0.663\n",
      "[64, 12000] loss: 0.663\n",
      "[65,  2000] loss: 0.591\n",
      "[65,  4000] loss: 0.628\n",
      "[65,  6000] loss: 0.613\n",
      "[65,  8000] loss: 0.665\n",
      "[65, 10000] loss: 0.710\n",
      "[65, 12000] loss: 0.673\n",
      "[66,  2000] loss: 0.568\n",
      "[66,  4000] loss: 0.603\n",
      "[66,  6000] loss: 0.638\n",
      "[66,  8000] loss: 0.653\n",
      "[66, 10000] loss: 0.654\n",
      "[66, 12000] loss: 0.683\n",
      "[67,  2000] loss: 0.562\n",
      "[67,  4000] loss: 0.645\n",
      "[67,  6000] loss: 0.644\n",
      "[67,  8000] loss: 0.602\n",
      "[67, 10000] loss: 0.659\n",
      "[67, 12000] loss: 0.659\n",
      "[68,  2000] loss: 0.566\n",
      "[68,  4000] loss: 0.628\n",
      "[68,  6000] loss: 0.625\n",
      "[68,  8000] loss: 0.678\n",
      "[68, 10000] loss: 0.655\n",
      "[68, 12000] loss: 0.721\n",
      "[69,  2000] loss: 0.563\n",
      "[69,  4000] loss: 0.603\n",
      "[69,  6000] loss: 0.655\n",
      "[69,  8000] loss: 0.661\n",
      "[69, 10000] loss: 0.681\n",
      "[69, 12000] loss: 0.700\n",
      "[70,  2000] loss: 0.582\n",
      "[70,  4000] loss: 0.631\n",
      "[70,  6000] loss: 0.644\n",
      "[70,  8000] loss: 0.668\n",
      "[70, 10000] loss: 0.698\n",
      "[70, 12000] loss: 0.685\n",
      "[71,  2000] loss: 0.562\n",
      "[71,  4000] loss: 0.648\n",
      "[71,  6000] loss: 0.597\n",
      "[71,  8000] loss: 0.658\n",
      "[71, 10000] loss: 0.655\n",
      "[71, 12000] loss: 0.678\n",
      "[72,  2000] loss: 0.592\n",
      "[72,  4000] loss: 0.619\n",
      "[72,  6000] loss: 0.611\n",
      "[72,  8000] loss: 0.686\n",
      "[72, 10000] loss: 0.716\n",
      "[72, 12000] loss: 0.663\n",
      "[73,  2000] loss: 0.596\n",
      "[73,  4000] loss: 0.612\n",
      "[73,  6000] loss: 0.637\n",
      "[73,  8000] loss: 0.670\n",
      "[73, 10000] loss: 0.664\n",
      "[73, 12000] loss: 0.669\n",
      "[74,  2000] loss: 0.594\n",
      "[74,  4000] loss: 0.573\n",
      "[74,  6000] loss: 0.656\n",
      "[74,  8000] loss: 0.651\n",
      "[74, 10000] loss: 0.698\n",
      "[74, 12000] loss: 0.653\n",
      "[75,  2000] loss: 0.587\n",
      "[75,  4000] loss: 0.652\n",
      "[75,  6000] loss: 0.629\n",
      "[75,  8000] loss: 0.659\n",
      "[75, 10000] loss: 0.690\n",
      "[75, 12000] loss: 0.698\n",
      "[76,  2000] loss: 0.563\n",
      "[76,  4000] loss: 0.635\n",
      "[76,  6000] loss: 0.634\n",
      "[76,  8000] loss: 0.663\n",
      "[76, 10000] loss: 0.669\n",
      "[76, 12000] loss: 0.673\n",
      "[77,  2000] loss: 0.593\n",
      "[77,  4000] loss: 0.587\n",
      "[77,  6000] loss: 0.677\n",
      "[77,  8000] loss: 0.660\n",
      "[77, 10000] loss: 0.667\n",
      "[77, 12000] loss: 0.692\n",
      "[78,  2000] loss: 0.546\n",
      "[78,  4000] loss: 0.607\n",
      "[78,  6000] loss: 0.661\n",
      "[78,  8000] loss: 0.645\n",
      "[78, 10000] loss: 0.656\n",
      "[78, 12000] loss: 0.676\n",
      "[79,  2000] loss: 0.589\n",
      "[79,  4000] loss: 0.596\n",
      "[79,  6000] loss: 0.610\n",
      "[79,  8000] loss: 0.645\n",
      "[79, 10000] loss: 0.666\n",
      "[79, 12000] loss: 0.667\n",
      "[80,  2000] loss: 0.563\n",
      "[80,  4000] loss: 0.617\n",
      "[80,  6000] loss: 0.655\n",
      "[80,  8000] loss: 0.727\n",
      "[80, 10000] loss: 0.696\n",
      "[80, 12000] loss: 0.661\n",
      "[81,  2000] loss: 0.573\n",
      "[81,  4000] loss: 0.639\n",
      "[81,  6000] loss: 0.709\n",
      "[81,  8000] loss: 0.668\n",
      "[81, 10000] loss: 0.707\n",
      "[81, 12000] loss: 0.689\n",
      "[82,  2000] loss: 0.601\n",
      "[82,  4000] loss: 0.651\n",
      "[82,  6000] loss: 0.682\n",
      "[82,  8000] loss: 0.662\n",
      "[82, 10000] loss: 0.710\n",
      "[82, 12000] loss: 0.683\n",
      "[83,  2000] loss: 0.569\n",
      "[83,  4000] loss: 0.606\n",
      "[83,  6000] loss: 0.655\n",
      "[83,  8000] loss: 0.660\n",
      "[83, 10000] loss: 0.683\n",
      "[83, 12000] loss: 0.659\n",
      "[84,  2000] loss: 0.585\n",
      "[84,  4000] loss: 0.634\n",
      "[84,  6000] loss: 0.653\n",
      "[84,  8000] loss: 0.642\n",
      "[84, 10000] loss: 0.680\n",
      "[84, 12000] loss: 0.728\n",
      "[85,  2000] loss: 0.574\n",
      "[85,  4000] loss: 0.608\n",
      "[85,  6000] loss: 0.684\n",
      "[85,  8000] loss: 0.695\n",
      "[85, 10000] loss: 0.686\n",
      "[85, 12000] loss: 0.671\n",
      "[86,  2000] loss: 0.556\n",
      "[86,  4000] loss: 0.636\n",
      "[86,  6000] loss: 0.632\n",
      "[86,  8000] loss: 0.694\n",
      "[86, 10000] loss: 0.657\n",
      "[86, 12000] loss: 0.686\n",
      "[87,  2000] loss: 0.627\n",
      "[87,  4000] loss: 0.650\n",
      "[87,  6000] loss: 0.729\n",
      "[87,  8000] loss: 0.677\n",
      "[87, 10000] loss: 0.689\n",
      "[87, 12000] loss: 0.665\n",
      "[88,  2000] loss: 0.591\n",
      "[88,  4000] loss: 0.657\n",
      "[88,  6000] loss: 0.683\n",
      "[88,  8000] loss: 0.706\n",
      "[88, 10000] loss: 0.692\n",
      "[88, 12000] loss: 0.725\n",
      "[89,  2000] loss: 0.631\n",
      "[89,  4000] loss: 0.654\n",
      "[89,  6000] loss: 0.684\n",
      "[89,  8000] loss: 0.688\n",
      "[89, 10000] loss: 0.701\n",
      "[89, 12000] loss: 0.666\n",
      "[90,  2000] loss: 0.621\n",
      "[90,  4000] loss: 0.620\n",
      "[90,  6000] loss: 0.674\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Test the network on the test data\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "We have trained the network for 2 passes over the training dataset.\n",
    "But we need to check if the network has learnt anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network\n",
    "outputs, and checking it against the ground-truth. If the prediction is\n",
    "correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(Variable(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are energies for the 10 classes.\n",
    "Higher the energy for a class, the more the network\n",
    "thinks that the image is of the particular class.\n",
    "So, let's get the index of the highest energy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem pretty good.\n",
    "\n",
    "Let us look at how the network performs on the whole dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks waaay better than chance, which is 10% accuracy (randomly picking\n",
    "a class out of 10 classes).\n",
    "Seems like the network learnt something.\n",
    "\n",
    "Hmmm, what are the classes that performed well, and the classes that did\n",
    "not perform well:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 55 %\n",
      "Accuracy of   car : 81 %\n",
      "Accuracy of  bird : 39 %\n",
      "Accuracy of   cat : 43 %\n",
      "Accuracy of  deer : 61 %\n",
      "Accuracy of   dog : 42 %\n",
      "Accuracy of  frog : 62 %\n",
      "Accuracy of horse : 56 %\n",
      "Accuracy of  ship : 71 %\n",
      "Accuracy of truck : 49 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so what next?\n",
    "\n",
    "How do we run these neural networks on the GPU?\n",
    "\n",
    "Training on GPU\n",
    "----------------\n",
    "Just like how you transfer a Tensor on to the GPU, you transfer the neural\n",
    "net onto the GPU.\n",
    "This will recursively go over all modules and convert their parameters and\n",
    "buffers to CUDA tensors:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "    net.cuda()\n",
    "\n",
    "\n",
    "Remember that you will have to send the inputs and targets at every step\n",
    "to the GPU too:\n",
    "\n",
    "::\n",
    "\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "Why dont I notice MASSIVE speedup compared to CPU? Because your network\n",
    "is realllly small.\n",
    "\n",
    "**Exercise:** Try increasing the width of your network (argument 2 of\n",
    "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` –\n",
    "they need to be the same number), see what kind of speedup you get.\n",
    "\n",
    "**Goals achieved**:\n",
    "\n",
    "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
    "- Train a small neural network to classify images\n",
    "\n",
    "Training on multiple GPUs\n",
    "-------------------------\n",
    "If you want to see even more MASSIVE speedup using all of your GPUs,\n",
    "please check out :doc:`data_parallel_tutorial`.\n",
    "\n",
    "Where do I go next?\n",
    "-------------------\n",
    "\n",
    "-  :doc:`Train neural nets to play video games </intermediate/reinforcement_q_learning>`\n",
    "-  `Train a state-of-the-art ResNet network on imagenet`_\n",
    "-  `Train a face generator using Generative Adversarial Networks`_\n",
    "-  `Train a word-level language model using Recurrent LSTM networks`_\n",
    "-  `More examples`_\n",
    "-  `More tutorials`_\n",
    "-  `Discuss PyTorch on the Forums`_\n",
    "-  `Chat with other users on Slack`_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
